# -*- coding: utf-8 -*-
"""deep_fakes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EzgZGKQUODykzf-BBx7WIngGLTLArpI2

# Implementation for paper "First Order Motion Model for Image Animation"
"""

# Mount Drive
from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My\ Drive/Capstone/deepfakes

# Commented out IPython magic to ensure Python compatibility.
# Run Once
!pip install PyYAML==5.3.1
!git clone https://github.com/AliaksandrSiarohin/first-order-model
# %cd first-order-model

# Commented out IPython magic to ensure Python compatibility.
# %cd first-order-model

ls

import imageio
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from skimage.transform import resize
from IPython.display import HTML
import warnings
from demo import load_checkpoints
from demo import make_animation
from skimage import img_as_ubyte
warnings.filterwarnings("ignore")

def display(source, driving, generated=None):
    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))

    ims = []
    for i in range(len(driving)):
        cols = [source]
        cols.append(driving[i])
        if generated is not None:
            cols.append(generated[i])
        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)
        plt.axis('off')
        ims.append([im])

    ani = animation.ArtistAnimation(fig, ims, interval=60, repeat_delay=1000)
    plt.close()
    return ani


def deep_fake(image, video, i):
  source_image = imageio.imread(f'/content/gdrive/My Drive/Capstone/deepfakes/media/{image}')
  driving_video = imageio.mimread(f'/content/gdrive/My Drive/Capstone/deepfakes/media/{video}', memtest=False) # Needed if video quality is to good.
  
  #Resize image and video to 256x256
  source_image = resize(source_image, (256, 256))[..., :3]
  driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]

  generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml', 
                            checkpoint_path='/content/gdrive/My Drive/Capstone/deepfakes/media/vox-cpk.pth.tar') 

  predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)

  #save resulting video
  imageio.mimsave(f'../generated-{i}.mp4', [img_as_ubyte(frame) for frame in predictions])
  #video can be downloaded from /content folder

  return HTML(display(source_image, driving_video, predictions).to_html5_video())

# for i in range(3, 4):
deep_fake(f"seed1.png", "tiktokdance.MP4", 3)

